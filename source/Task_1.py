from metaflow import FlowSpec, step, Parameter
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
import pandas as pd
import mlflow
import mlflow.sklearn
import joblib  

class SklearnPipelineFlow(FlowSpec):
    train_data_path = Parameter(
        'train_data_path', 
        help="Path to train.csv", 
        default='../dataset/train.csv'
    )
    test_data_path = Parameter(
        'test_data_path',
        help="Path to test.csv", 
        default='../dataset/test.csv'
    )
    gender_submission_path = Parameter(
        'gender_submission_path', 
        help="Path to gender_submission.csv", 
        default='../dataset/gender_submission.csv'
    )

    @step
    def start(self):
        print("üöÄ Kh·ªüi ƒë·ªông pipeline ML v·ªõi sklearn + Metaflow + MLflow!")
        self.next(self.check_versions)

    @step
    def check_versions(self):
        import sys
        import pandas as pd
        import sklearn
        import numpy as np
        import metaflow
        import mlflow
        import joblib  

        print("üì¶ Phi√™n b·∫£n th∆∞ vi·ªán ƒëang s·ª≠ d·ª•ng:")
        print(f"Python: {sys.version}")
        print(f"pandas: {pd.__version__}")
        print(f"scikit-learn: {sklearn.__version__}")
        print(f"numpy: {np.__version__}")
        print(f"metaflow: {metaflow.__version__}")
        print(f"mlflow: {mlflow.__version__}")  # In version c·ªßa mlflow
        print(f"joblib: {joblib.__version__}")  # In version c·ªßa joblib

        self.next(self.load_data)

    @step
    def load_data(self):
        print("Begin step 1")
        self.train_df = pd.read_csv(self.train_data_path)
        self.test_df = pd.read_csv(self.test_data_path)
        self.gender_submission_df = pd.read_csv(self.gender_submission_path)

        self.train_df.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'], inplace=True)
        self.X_train = self.train_df.drop('Survived', axis=1)
        self.y_train = self.train_df['Survived']

        self.test_df.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'], inplace=True)
        self.X_test = self.test_df
        print(f"D·ªØ li·ªáu train: {self.X_train.shape[0]} m·∫´u, {self.X_train.shape[1]} ƒë·∫∑c tr∆∞ng")
        print("End step 1")
        self.next(self.build_pipeline)

    @step
    def build_pipeline(self):
        print("Begin step 2")
        self.num_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
        self.cat_features = ['Sex', 'Embarked']

        num_pipeline = Pipeline([('imputer', SimpleImputer()), ('scaler', StandardScaler())])
        cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder(handle_unknown='ignore'))])

        self.preprocessor = ColumnTransformer([('num', num_pipeline, self.num_features), ('cat', cat_pipeline, self.cat_features)])
        print("End step 2")
        self.next(self.train_model)

    @step
    def train_model(self):
        print("Begin step 3")

        # ƒê·∫£m b·∫£o kh·ªüi t·∫°o MLflow
        mlflow.start_run()

        # Log dataset th√¥ng tin
        mlflow.log_param("train_data_path", self.train_data_path)
        mlflow.log_param("test_data_path", self.test_data_path)
        mlflow.log_param("gender_submission_path", self.gender_submission_path)

        # ƒê·ªãnh nghƒ©a m√¥ h√¨nh RandomForest v√† KNN
        rf_model = RandomForestClassifier(random_state=22521391)
        knn_model = KNeighborsClassifier()

        # T·∫°o pipeline ƒë·∫ßy ƒë·ªß v·ªõi preprocessor v√† classifier cho RandomForest
        rf_pipeline = Pipeline([('preprocessor', self.preprocessor), ('classifier', rf_model)])

        # T·∫°o pipeline ƒë·∫ßy ƒë·ªß v·ªõi preprocessor v√† classifier cho KNN
        knn_pipeline = Pipeline([('preprocessor', self.preprocessor), ('classifier', knn_model)])

        # Grid search cho Random Forest
        param_grid_rf = {
            'preprocessor__num__imputer__strategy': ['mean', 'median'],
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [None, 5, 10],
        }

        # Grid search cho KNN
        param_grid_knn = {
            'preprocessor__num__imputer__strategy': ['mean', 'median'],
            'classifier__n_neighbors': [3, 5, 7],
            'classifier__weights': ['uniform', 'distance'],
        }

        # Log t√™n m√¥ h√¨nh
        mlflow.log_param("model", "RandomForest and KNN")

        # Th·ª±c hi·ªán grid search cho Random Forest
        mlflow.log_param("model_type", "RandomForest")
        self.grid_search_rf = GridSearchCV(estimator=rf_pipeline, param_grid=param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)
        self.grid_search_rf.fit(self.X_train, self.y_train)
        print(f"‚úÖ Random Forest - T·ªët nh·∫•t: {self.grid_search_rf.best_params_}")

        # Th·ª±c hi·ªán grid search cho KNN
        mlflow.log_param("model_type", "KNN")
        self.grid_search_knn = GridSearchCV(estimator=knn_pipeline, param_grid=param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)
        self.grid_search_knn.fit(self.X_train, self.y_train)
        print(f"‚úÖ KNN - T·ªët nh·∫•t: {self.grid_search_knn.best_params_}")

        # Log k·∫øt qu·∫£
        self.best_model_rf = self.grid_search_rf.best_estimator_
        self.best_model_knn = self.grid_search_knn.best_estimator_

        # L∆∞u m√¥ h√¨nh v√† log l·∫°i ƒë∆∞·ªùng d·∫´n
        joblib.dump(self.best_model_rf, 'best_rf_model.pkl')
        joblib.dump(self.best_model_knn, 'best_knn_model.pkl')

        # L∆∞u m√¥ h√¨nh v√†o MLflow
        mlflow.log_artifact('best_rf_model.pkl')
        mlflow.log_artifact('best_knn_model.pkl')

        mlflow.log_param("RandomForest_best_params", self.grid_search_rf.best_params_)
        mlflow.log_param("KNN_best_params", self.grid_search_knn.best_params_)
        mlflow.log_param("RandomForest_best_score", self.grid_search_rf.best_score_)
        mlflow.log_param("KNN_best_score", self.grid_search_knn.best_score_)

        print("End step 3")
        self.next(self.evaluate)

    @step
    def evaluate(self):
        print("Begin step 4")
        # ƒê√°nh gi√° m√¥ h√¨nh Random Forest v√† KNN
        rf_preds = self.best_model_rf.predict(self.X_test)
        knn_preds = self.best_model_knn.predict(self.X_test)

        rf_accuracy = accuracy_score(self.gender_submission_df['Survived'], rf_preds)
        knn_accuracy = accuracy_score(self.gender_submission_df['Survived'], knn_preds)

        print(f"üéØ Accuracy tr√™n t·∫≠p test v·ªõi RandomForest: {rf_accuracy:.4f}")
        print(f"üéØ Accuracy tr√™n t·∫≠p test v·ªõi KNN: {knn_accuracy:.4f}")

        # Log accuracy v√†o MLflow
        mlflow.log_metric("RandomForest_Accuracy", rf_accuracy)
        mlflow.log_metric("KNN_Accuracy", knn_accuracy)

        print("End step 4")
        self.next(self.end)

    @step
    def end(self):
        print("üéâ Pipeline ho√†n t·∫•t.")
        mlflow.end_run()  # K·∫øt th√∫c MLflow run

if __name__ == '__main__':
    SklearnPipelineFlow()
